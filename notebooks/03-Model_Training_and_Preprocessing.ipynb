{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37c39d20",
   "metadata": {},
   "source": [
    "# Clothes Size Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2ae73",
   "metadata": {},
   "source": [
    "## Quick Note (PLEASE READ)\n",
    "\n",
    "This is the new notebook where I did the feature engineering and the training model, here's why:\n",
    "\n",
    "I had the time to check where my model failed, and I noticed that my model is failing precisely because of the problems I identified (feature overlap and class imbalance). The only way to get out of that error is to attack those problems directly. \n",
    "\n",
    "### So let's begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e31d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas restantes despu√©s de eliminar XXL (support=14): 26284\n",
      "üöÄ Running essential Pre-processing pipeline (Scaling & Encoding)...\n",
      "üî¢ Encoded target column 'size'.\n",
      "üíæ LabelEncoder saved.\n",
      "üìè Scaled numeric features: ['weight', 'height', 'age']\n",
      "üíæ StandardScaler saved.\n",
      "‚úÖ Pre-processing pipeline completed.\n"
     ]
    }
   ],
   "source": [
    "# 1. Preparaci√≥n e Importaci√≥n\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# A√±adimos el path del proyecto para importar m√≥dulos personalizados\n",
    "PROJECT_PATH = os.path.abspath(os.path.join(os.pardir))\n",
    "sys.path.append(PROJECT_PATH)\n",
    "from src.pipeline.feature_engineering import *\n",
    "\n",
    "# Cargamos el dataset\n",
    "DATA_PATH = '../data/processed/clothes_processed.csv' \n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# FILTRADO CR√çTICO: Eliminamos las filas con muy pocos datos para evitar sesgos\n",
    "df = df[df['size'] != 'XXL'].copy() \n",
    "print(f\"Filas restantes despu√©s de eliminar XXL (support=14): {len(df)}\")\n",
    "\n",
    "\n",
    "# 2. Ejecutar el Pipeline de Transformaci√≥n\n",
    "TARGET_COL = 'size'\n",
    "processor = FeatureEngineer(df, target_col=TARGET_COL) \n",
    "df_processed = processor.run_all_preprocessing() \n",
    "\n",
    "# 3. Separaci√≥n de Variables X e y\n",
    "X = df_processed[['weight', 'height', 'age']] \n",
    "y = df_processed[f'{TARGET_COL}_encoded']      \n",
    "\n",
    "# 4. Divisi√≥n de Datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc676eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Initializing grid search for Random Forest...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/best_rf_model_optimized.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Hyperparameter grid for Random Forest\n",
    "param_grid = {\n",
    "    # NNumber of trees in the forest\n",
    "    'n_estimators': [100, 200], \n",
    "\n",
    "    # Maximum depth of the trees\n",
    "    'max_depth': [5, 10, None],  # None allows nodes to expand until all leaves are pure\n",
    "\n",
    "    # Class weighting (to continue combating imbalance)\n",
    "    'class_weight': [None, 'balanced'] \n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n Initializing grid search for Random Forest...\")\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Save the best model\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "joblib.dump(best_rf_model, '../models/best_rf_model_optimized.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b90f8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Par√°metros: {'class_weight': 'balanced', 'max_depth': 5, 'n_estimators': 200}\n",
      "Mejor Score (F1-Weighted): 0.3792\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mejores Par√°metros: {grid_search_rf.best_params_}\")\n",
    "print(f\"Mejor Score (F1-Weighted): {grid_search_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107c101c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- REPORT ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           L       0.28      0.36      0.31       827\n",
      "           M       0.32      0.12      0.17       958\n",
      "           S       0.34      0.22      0.27       805\n",
      "          XL       0.31      0.32      0.31       924\n",
      "         XXS       0.35      0.78      0.48       506\n",
      "        XXXL       0.71      0.70      0.70      1237\n",
      "\n",
      "    accuracy                           0.41      5257\n",
      "   macro avg       0.38      0.42      0.38      5257\n",
      "weighted avg       0.41      0.41      0.39      5257\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = joblib.load('../models/label_encoder.pkl') \n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- REPORT ---\")\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae4907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clothes-size-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
